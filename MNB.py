# -*- coding: utf-8 -*-
"""Assigment1_guide.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cqag15TbTrOTFRbPIA7pLdZ9mRgM48G_

#**ASSIGMENT ONE:** Bag of Words implementation for Sentiment analysis ðŸ’­

Once Jeff finished his coffee, he settled into his desk at Amazon's bustling headquarters in Seattle. As a data analyst at the world's largest online retailer, Jeff was accustomed to diving deep into the ocean of data generated by millions of transactions every day.

Today, Jeff had a new challenge on his plate. The marketing team wanted to gain insights into customer sentiment regarding their latest products. Specifically, they were interested in understanding whether customers were generally satisfied or dissatisfied with their purchases.

After pondering over various approaches, Jeff decided to task his team of interns with a hands-on assignment to implement Bag of Words (BoW) and Naive Bayes classification for sentiment analysis on Amazon reviews.

As an intern is your task to complete this challenge the best way possible to impress your boss and hopefully get a full time position at the company.

The following notebook will guide you into how to create your BoW implementation for sentiment analysis and hopefully make jeff happy ðŸ¤­

As a first step we need to get all of our data ready
"""

#download train and test set
!gdown  https://drive.google.com/file/d/1bcnYdTHuY2pr4py5tG-HtNU73pJzRH7U/view?usp=sharing --fuzzy
!gdown  https://drive.google.com/file/d/1T19F6Oge0-qHMqX_IKiU_l94Y1k2oLJp/view?usp=sharing --fuzzy

#unzip
!unzip train.ft.zip
!unzip test.ft.zip

"""Our txts has the following format


```
__label__#  This is a review ....

```

As you see the first word refers to the label, `__label__1` corresponds to 1- and
2-star reviews(negative sentiment) and `__label__2` corresponds to to 4- and 5-star reviews (positive sentiment).

Normally reviews are very messy including words with incorrect spelling, different formats and a lot of words that do not add any value to our classification. Let's create a method to clean them
"""

print(f"""
'\n# Observation of current step:\n\n## AXTree:\nNote: [bid] is the unique alpha-numeric identifier at the beginning of lines for each element in the AXTree. Always use bid to refer to elements in your actions.\n\nNote: You can only interact with visible elements. If the "visible" tag is not\npresent, the element is not visible on the page.\n\nRootWebArea \'Google\'\n\t[23] navigation \'\', visible\n\t\t[25] link \'About\', clickable, visible\n\t\t[26] link \'Store\', clickable, visible\n\t\t[34] link \'Gmail\', clickable, visible\n\t\t[36] link \'Search for Images\', clickable, visible\n\t\t[41] button \'Google apps\', clickable, visible, expanded=False\n\t\t\tStaticText \'\'\n\t\t\t[42] image \'\', visible\n\t\t[43] link \'Sign in\', clickable, visible\n\t\t\tStaticText \'\'\n\t\t\tStaticText \'Sign in\'\n\t[51] image \'Google\', visible\n\t[81] search \'\', visible\n\t\t[91] image \'\', visible\n\t\t[95] combobox \'Search\', visible, autocomplete=\'both\', hasPopup=\'listbox\', expanded=False, controls=\'Alh6id\'\n\t\t[106] button \'Search by voice\', clickable, visible\n\t\t\t[107] image \'\', visible\n\t\t[109] button \'Search by image\', clickable, visible\n\t\t\t[110] image \'\', visible\n\t\t[240] button \'Google Search\', clickable, visible\n\t\t[241] button "I\'m Feeling Lucky", clickable, visible\n\tStaticText \'Google offered in:\'\n\t[263] link \'FranÃ§ais\', clickable, visible\n\t[266] contentinfo \'\', visible\n\t\tStaticText \'Canada\'\n\t\t[271] link \'Advertising\', clickable, visible\n\t\t[272] link \'Business\', clickable, visible\n\t\t[273] link \'How Search works\', clickable, visible\n\t\t[275] link \'Privacy\', clickable, visible\n\t\t[276] link \'Terms\', clickable, visible\n\t\t[281] button \'Settings\', visible, hasPopup=\'menu\', expanded=False\n\t\t\t[282] generic, visible, hasPopup=\'menu\'\n\t\t\t\tStaticText \'Settings\'\n\n## Focused element:\nbid=\'20\'\n\n\n'
"""

)

#import nltk libray, you are going to need this later
import nltk
import pandas as pd
nltk.download('stopwords')

import string
import re
from nltk.corpus import stopwords
def preprocess_text(text):
  """ Method to clean reviews from noise and standarize text across the different classes.
      The preprocessing includes converting to lowercase, removing punctuation, and removing stopwords.
  Arguments
  ---------
  text : String
     Text to clean
  Returns
  -------
  text : String
      Cleaned text
  """
  stop_words = set(stopwords.words('english'))

  text = #make everything lower case
  text = #remove \n characters
  text = re.sub(r'[^\w\s]', ' ', text) #remove any punctuation or special characters
  text = #remove all numbers
  text = #remove all stopwords (see imports to help you with this)

  return text

"""It's also useful to have our data organized and ready to access! An great library for this is [pandas](https://pandas.pydata.org/). In the folowing code cell you will create a dataframe containing all the data provided in the training document. Please be patient this code cell can take up to 10 min (is a big dataset!)"""

def create_dataframe(path_to_file):
  """ Creates dataframe of reviews and labels
  Arguments
  ---------
  path_to_file : str
      path to file to read
  Returns
  -------
  df : pandas dataframe
      Dataframe of reviews and labels
  """
  df={}
  index= 0
  with open(path_to_file) as f:
    for line in f:
      label_text = #get label from line in file
      text = #get text of the review
      label =# get numeric value of label_text. If label_text is __label__1 then label = 0 if __label__2 label = 1
      text = #preprocess text
      df[index] = #create dictionary with keys "label" and "text" and set the correct values
      index+=1
  return pd.DataFrame.from_dict(df,orient='index')

df_train= create_dataframe('train.ft.txt')
df_test= create_dataframe('test.ft.txt')

def vocab_dictionary(df):
  """ Creates dictionary of frequencies based on a dataset of reviews
  Arguments
  ---------
  dataset : list of tuples
      list of tuples of the form (label, text)
  Returns
  -------
  vocab_dict : dictonary
      Dictionary of words and their frequencies with the format {word: frequency}
  """

  vocab= {} #create empty dictionary
  #iterate through rows of df and count the frequency of words

  return vocab


full_vocab=vocab_dictionary(df_train)
positive_vocab = vocab_dictionary(df_train[df_train['label']==1]) #We create a positive vocab to keep track of words in positive reviews. This will come in handy later
negative_vocab = vocab_dictionary(df_train[df_train['label']==0]) #We create a negative vocab to keep track of words in negative reviews. This will come in handy later

"""Let's take a look to out training vocabulary, in the following cell create a sorted dictionary by frequency from most frequent to less frequent tokens"""

vocab_sorted = #sort full_vocab from words with high frequency to low frequency

from itertools import islice

first_tokens = # Take first 30 tokens of each vocabulary

"""In order to see Zip's law first hand, let's plot the first 30 most frequent words of each vocabulary"""

import matplotlib.pyplot as plt

fig = plt.figure(figsize = (25, 5))

#TODO: Create bar chart of the 30 most frequent words in the reviews with appropriate title and axis labels

plt.show()

"""Let's check the size of our vocabulary"""

print('Vocabulary size:',len(full_vocab))

"""Now that our reviews are "clean" let's start the real work. Naive bayes includes three important components![1_uaoxGu2kkQV2Yrk2EggG_Q.webp](data:image/webp;base64,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)

We need to calculate two things for the posterior probability: the likelihood and the class prior probability (since is naive bayes we ignore the predictor prior probability)

Let's first calculate the class prior probability. This meaning the probability a review is positive or negative without taking into account the content.
"""

positive_prior = #calculate positive prior
negative_prior = #calculate negative prior

"""Now let's create a method to calculate the log likelihood of each word in our vocabulary"""

import math
SMOOTHING_FACTOR = 0.2
def calculate_log_likelihood(vocab, positive_vocab, negative_vocab, smoothing_factor=SMOOTHING_FACTOR):
  """ Calculates log likelihood of words belonging to a positive or negative review given a dataset and vocabulary
  Arguments
  ---------
  dataset : list of tuples
      List of positive or negative reviews with their respective label (label, text)
  vocab : dictionary
      Vocabulary of words in the dataset with their respective frequencies
  Returns
  -------
  likelihood : dictionary of dictionaries
      Dictionary of words and their positive and negative log likelihood with format {word: {'positive': log_likelihood, 'negative': log_likelihood}}
  """
  likelihood = {}
  # TODO: create a dictionary with the log likelihoods of each word
  number_instances_positive = #number of words in positive_vocab
  number_instances_negative = #number of words in negative_vocab
  number_types = #number of words in all vocab


  for word, count in vocab.items():
    likelihood[word] = {}
    # TODO: Calculate positive and negative log likelihood for EACH word.
    # IMPORTANT: remember some words might be in positives but not negatives (or the other way around, thats why we use the smoothing factor!)

  return likelihood

likelihood = calculate_log_likelihood(full_vocab,positive_vocab,negative_vocab)

"""Let's make sure we don't have any bugs till now"""

assert  round(sum([math.exp(likelihood[word]['positive']) for word in likelihood]))==1 , "There is probably a bug calculating the positive log likelihood"
assert  round(sum([math.exp(likelihood[word]['negative']) for word in likelihood]))==1 , "There is probably a bug calculating the negative log likelihood"
print("Great job! Keep going!")

"""Now the most essential function in our program, the method to actually classify unseen reviews."""

def classify_review(text, likelihood, positive_prior, negative_prior):

    """ Calculates log scores for a new text given some prior probabilities and likelihoods
    Arguments
    ---------
    text : string
        Text to classify
    likelihood_positive : dictionary
        Dictionary of words and their log likelihood for positive reviews
    likelihood_negative : dictionary
        Dictionary of words and their log likelihood for negative reviews
    positive_prior : float
        Prior probability of a review being positive
    negative_prior : float
        Prior probability of a review being negative
    Returns
    -------
    predicted sentiment : string
        Predicted sentiment of the text
    sentiment_scores : tuple or dictionary
        Tuple of positive and negative sentiment scores
    """
    tokens = # Split the input review

    # Calculate the log scores for each sentiment category (take into account value for unseen tokens)
    log_score_positive =
    log_score_negative =

    sentiment_scores = {
        'positive': log_score_positive,
        'negative': log_score_negative,
    }


    predicted_sentiment = # Determine the predicted sentiment based on the highest sentiment score


    return predicted_sentiment, sentiment_scores

text="This hair dryer is terribly bad, it doesn't work at all"
predicted_sentiment, sentiment_scores = classify_review(text, likelihood,
                               positive_prior, negative_prior)
print(predicted_sentiment)
print(sentiment_scores)
#You should see here a correct prediction of negative

text='This product was amazing I would buy it again'
predicted_sentiment, sentiment_scores = classify_review(text, likelihood,
                               positive_prior, negative_prior)
print(predicted_sentiment)
print(sentiment_scores)
#You should see here a correct prediction of positive

"""## Let's test our model

In all machine learning workflows is essential to test how well our model does with unseen data. Let's try testing the model with the provided test dataframe we created at the beggining, you remember?
"""

true_negatives = 0
false_negatives = 0
true_positives = 0
false_positives = 0

for index,review in df_test.iterrows():
  true_label = review['label']
  text = review['text']
  #TODO: Iterate through test set, compare true label with predicted label and get evaluation metrics (precision, recall and F1)
  # Be patient! This code might take a while (about 5 minutes)

print("Precision: ", precision)
print("Recall: ", recall)
print("F1 Score: ", f1_score)

"""## Let's Experiment

Document any changes after this cell

Now it's your time to experiment to impress Jeff:

1.   modify the smoothing factor (use three different values)
1.   try using the raw texts withour any pre-processing techniques

Analyse and report how these modifications affect the predictions of your model(see more in handout)
"""